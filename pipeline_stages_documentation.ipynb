{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further features and hyperparameters tuning\n",
    "- After completing the initial pipeline, the evaluated performance is poor, indicating the need for further tuning\n",
    "- The initial pipeline and its performance will be described, followed by noting its measured performance\n",
    "- Every following tuning of the pipeline will be mentioned, evaluated and labeled as meaningful or not based on the improvement it adds\n",
    "#### The initial pipeline\n",
    "- Features:\n",
    "    - Patients-related: age, gender, time in the hospital before admission in ICU, ethnicity\n",
    "    - Events: time-stamped values of items are aggregated into: average, standard deviation, trend, range (max-min), count\n",
    "        - Data not present replaced with 0\n",
    "    - Target (ICU stay): log transformed\n",
    "- Feature selection:\n",
    "    - first items with most appearances: 32\n",
    "        - 168 features\n",
    "    - filter by variance: <1%\n",
    "        - 153 features left\n",
    "    - fileter by correlation: >0.9\n",
    "        - 79 features left\n",
    "    - filter by contribution to RMSE (permutation imporance): <1%\n",
    "        - 9 features left\n",
    "- Cosen model: XGBoost\n",
    "- Hyperparameters:\n",
    "    - Grid search:\n",
    "        - max depth: 3, 5, 7, 10\n",
    "        - learning rate: .01, .1\n",
    "        - nr of estimators: 100, 200\n",
    "        - reg_alpha: .1\n",
    "- Evaluation on test data:\n",
    "    - MAE:  9.69  days\n",
    "    - RMSE: 13.47 days\n",
    "    - R^2:  -0.29\n",
    "#### Pipeline modification\n",
    "- Removing cross-validation and and grid search, default XGBoost parameters\n",
    "    - Evaluation:\n",
    "        - MAE:  10.08 days\n",
    "        - RMSE: 13.73 days\n",
    "        - R^2:  -0.34\n",
    "    - Verdict: Cross-validation and grid search are helpful\n",
    "- Removing only grid search\n",
    "    - Evaluation:\n",
    "        - MAE:  10.63 days\n",
    "        - RMSE: 13.09 days\n",
    "        - R^2:  -0.5\n",
    "    - Verdict: Grid search is helpful\n",
    "- Removing filtering by contribution to RMSE (permutation importance)\n",
    "    - Evaluation:\n",
    "        - MAE:  9.45\n",
    "        - RMSE: 12.79\n",
    "        - R^2:  -0.16\n",
    "    - Verdict: Tuning of the treshold for this filter may prove useful\n",
    "- Eliminate filtering by correlation and permutation importance\n",
    "    - Evaluation:\n",
    "        - MAE:  8.6\n",
    "        - RMSE: 11.74\n",
    "        - R^2:  0.02\n",
    "    - Verdict: Correlation proves to be a problem, needs tuning or removal\n",
    "#### Pipeline modification after dropping pattients with LOS > 30 days\n",
    "- Given that 75% of patients stay in the ICU for less than 22 days, removing patients with LOS greater than 30 days seems like a good trade-off \n",
    "- New results after limiting entries and discarding all feature filters\n",
    "    - Evaluation:\n",
    "        - MAE:  5.94\n",
    "        - RMSE: 6.9\n",
    "        - R^2:  -0.17\n",
    "    - Verdict: Based on the R^2, promissing gains can be added with filters\n",
    "- Adding only filtering by variance\n",
    "    - Evaluation:\n",
    "        - MAE:  5.90\n",
    "        - RMSE: 7.04\n",
    "        - R^2:  -0.19\n",
    "    - Verdict: Same results\n",
    "- Adding filtering by correlation\n",
    "    - Evaluation:\n",
    "        - MAE:  6.28\n",
    "        - RMSE: 7.21\n",
    "        - R^2:  -0.24\n",
    "    - Verdict: Filtering by correlation gives worse results\n",
    "- Adding all filters\n",
    "    - Remaining with only 7 relevant features\n",
    "    - Evaluation:\n",
    "        - MAE:  5.93\n",
    "        - RMSE: 6.95\n",
    "        - R^2:  -0.16\n",
    "    - Verdict: **Best version so far**\n",
    "- Leaving only variance and permutation importance feature filters\n",
    "    - Remaining with 14 relevant features\n",
    "    - Evaluation:\n",
    "        - MAE:  6.05\n",
    "        - RMSE: 7.07\n",
    "        - R^2:  -0.19\n",
    "    - Verdict: Filtering by correlation helps XGBoost in permutation importance filtering\n",
    "- Adding all filters and *imputing missing values with 0*\n",
    "    - Remaining with only 7 relevant features\n",
    "    - Evaluation:\n",
    "        - MAE:  6.20\n",
    "        - RMSE: 6.90\n",
    "        - R^2:  -0.14\n",
    "    - Verdict: Worse results, XGBoost works well with missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data preprocessing**\n",
    "\n",
    "### Data transformation\n",
    "- scaling, encoding\n",
    "- The age of the patients is computed from the ICU admission time minus their birth date\n",
    "    - Patients with ages greater than 89 years old are entered in the database to 300 in order to protect confidentiality\n",
    "    - All the patients in this case will have their age moved to 91.4, the average of their group\n",
    "- Categorical features of patients are encoded\n",
    "    - Gender is label encoded, while ethnicity is encoded using one hot encoding for better model interpretation\n",
    "- The distribution of the target variable, LOS, is right-skewed\n",
    "    - In order to have that data better interpretable by a wider range of models, a *log transformation* will be applied on it\n",
    "### Data cleaning\n",
    "- Since the time window of 24 hours was chosen for prediction, all chart events past that time will be discarded\n",
    "- There are 4 very far outliers with LOS above 60 days and they will be discarded since they are not enough to prove helpful for the model training\n",
    "- Based on the fact that 75% of the admissions have a LOS under 21 days and 87.2% have a LOS under 30 days, entries with more than that will also be discarded\n",
    "- Not all ICU stays have all the item values present\n",
    "    - The two possible approaces of dealing with that missing data are imputing 0 in their place or leaving them as null\n",
    "    - Since XGBoost, the model planned to be trained, works well with missing values, these will be left as null\n",
    "    - In order to mark their missing as a relevant feature, a count of the number of their appearances will be added for each item, 0 meaning a missing value\n",
    "### Feature engineering\n",
    "- The time-stamps of each chart event will be normalized as starting from the addmission time\n",
    "- Given the time-stamped nature of the item entries, the item values for each ICU stay will be aggregated into the following 5 features per item:\n",
    "    - average\n",
    "    - standard deviation\n",
    "    - trend\n",
    "    - range\n",
    "    - count\n",
    "- Since not all ICU stays have the same items in their respective events, only the items with more than 78% appearance will be selected as features\n",
    "    - This criteria means selecting the first 32 items, multiplied by the number of 5 metrics for each, giving 160 features\n",
    "    - This sorting is performed by an SQL query, that saves the results into `items_appearance_pneumonia.csv`\n",
    "#### Feature selection\n",
    "- 160 features, plus the encoded categorical ones, for each entry being too many for such a small number of entries (about 140), careful feature selection is necessary\n",
    "- The filtering of the features will be performed in three steps (proven useful by iterative experiments):\n",
    "    1. Filtering out the features with a *variance lower* than 1%\n",
    "    2. Building a *correlation matrix* on the remaining features and determine the pairs with correlation higher than 0.9\n",
    "        - Out of these pairs, only one of them is worth keeping, so the other one is dropped\n",
    "    3. Training a dummy XGBoost model in order to extract the permutation importance of the features\n",
    "        - Drop the features with a contribution to the RMS less than 1%\n",
    "### Data splitting\n",
    "- train, validation, test\n",
    "- The test holdout will be 20% out of the total number of entries\n",
    "    - Although this leaves the model with less training data, a larger test dataset is essential for comprehensive model evaluation\n",
    "- The model will be trained using 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Model selection**\n",
    "### Choosing the appropriate algorithm\n",
    "- XGBoost (Extreme Gradinent Boosting) is a great fit for this pipeline, having the following advantages:\n",
    "    - Good handling of tabular data\n",
    "    - Good performance on moderate-sized data\n",
    "    - Robustness for missing values and mixed data types (encoded categorical and numerical values)\n",
    "    - Explainable feature importance for interpretability\n",
    "    - Very good handling of non-linear relationships\n",
    "    - Includes regulation for preventing overfitting\n",
    "- Alternatives considered:\n",
    "    - Random forests\n",
    "        - Are simpler but offer less accurate results\n",
    "        - Filtering of feature importance is already done during the preprocessing part of the pipeline\n",
    "    - Neural Networks\n",
    "        - Need much larger ammounts of instances and data, would need to consider a different diagnostic\n",
    "### Defining the evaluation strategy\n",
    "- The key metrics that will be tracked to evaluate the performance of the model are:\n",
    "    - RMSE (Root Mean Squared Error)\n",
    "        - Penalizes large errors, especially useful in such critical medical cases\n",
    "        - RMSE chosen instead of MSE for better interpretability by converting the result back to the original units (days)\n",
    "    - MAE (Mean Absolute Error)\n",
    "        - Easily interpretable as the average days mispredicted\n",
    "    - R^2\n",
    "        - Explains the variance captured by the model \n",
    "        - Results from 0 increasing to one indicate increasing performance, while results lower than 0 indincate performance worse than predicting the average\n",
    "- These metrics can be extracted from the five-fold cross-validation training, but more reliably on the test data holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Model training**\n",
    "### Training the model on the training set\n",
    "- As previously stated, the model will be trained using 5-fold cross-validation\n",
    "    - This solves the problem of biased results of a single train-test split\n",
    "    - The cross-validation approach aims to reduce overfitting and variance in the chosen perfomance metrics\n",
    "    - The data utilization is maximized, every ICU stay being used four times for training and one time for testing\n",
    "- Grouping ICU stays by patient ids is essential, since one patient can have multiple ICU stays\n",
    "    - This grouping can prevent data leakage, not allowing ICU stays of patients to be split across training, validation and test data\n",
    "    - This approach better represents real-world performance\n",
    "### Hyperparameter tuning\n",
    "- Grid search is chosen for automating the hyperparameter tuning of the model\n",
    "    - It works by systematically testing the combinations of predefined hyperparameters in order to find the best performing model\n",
    "    - Seamlessly integrates the five-fold cross-validation\n",
    "    - Automatically balances the bias-variance tradeoff\n",
    "    - Provides explainable results, making the best combination of hyperparameters available for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Model evaluation and interpretation**\n",
    "### Evaluating using metrics on test data prediction\n",
    "- MAE, RMSE, R^2\n",
    "### Perform error analysis\n",
    "- ??\n",
    "### Explaining model behaviour\n",
    "- SHAP, LIME\n",
    "- feature importance\n",
    "- SHAP (Shape additive explanations) is a very useful tool for explaining how machine learning models make predictions\n",
    "    - It assigns a feature importance value for a specific predicion, showing how much a feature contributed to the model's output\n",
    "    - A baseline (expected value) is computed to represent the average prediction of the model over the dataset, SHAP using it to explain how features push the prediction above or below this baseline \n",
    "    - Positive values indicate a fature increasing the LOS predicion, while negative values indicate decreasing it\n",
    "    - SHAP can also be used for global interpretability, generatin a bar plot for feature values across all patients\n",
    "- LIME (Local Interpretable Model-agnostic Explanations) is used to explain only individual predictions \n",
    "    - approximating the model behaviour with another simpler, interpretabe model (like linear regression or decision rules) \n",
    "    - It explains individual predictions by creating small variations of the input, querying the model, and fitting the simple interpretable model to approximate the model's behavior locally.\n",
    "    - It highlights key features for a specific case using the surrogate model’s coefficients.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
